{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Creating SparkContext...\nSparkContext created.\nMaster URL: local[*]\n"
    },
    {
     "data": {
      "text/markdown": "**Do not forget to close the session with spark.stop()**",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -i start_spark.py --master local[*] --driver-memory 10g\n",
    "#%run -i start_spark.py --master local[*] --driver-memory 2g\n",
    "#%run -i start_spark.py --master spark://192.168.0.100:7077 --driver-memory 10g\n",
    "\n",
    "USE_IBM_COS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import coursera_common as cc\n",
    "import os\n",
    "\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StandardScaler, StringIndexer, StringIndexerModel, VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf, substring, stddev, mean, col"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "\n",
    "## ETL: Convert CSV to Parquet\n",
    "\n",
    "The raw data available in a CSV file is converted in a Parquet dataset for efficiency reasons. The CSV file can be located in the IBM Watson Studio Cloud Object storage to allow parallel read over Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Restoring data/payments.v2.parquet...\nComplete!\nSchema:\nroot\n |-- step: integer (nullable = true)\n |-- type: string (nullable = true)\n |-- amount: double (nullable = true)\n |-- nameOrig: string (nullable = true)\n |-- oldbalanceOrg: double (nullable = true)\n |-- newbalanceOrig: double (nullable = true)\n |-- nameDest: string (nullable = true)\n |-- oldbalanceDest: double (nullable = true)\n |-- newbalanceDest: double (nullable = true)\n |-- isFraud: integer (nullable = true)\n |-- isFlaggedFraud: integer (nullable = true)\n\npayments view created!\n+----+-------+---------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n|step|   type|   amount|   nameOrig|oldbalanceOrg|newbalanceOrig|   nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|\n+----+-------+---------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n| 156|CASH_IN| 27287.59|C1634109320|   8673566.52|    8700854.11|C1542157370|     558897.81|     531610.22|      0|             0|\n| 156|CASH_IN|165163.88|C1684617623|   8700854.11|    8866017.99|C1163394047|     272799.53|     107635.65|      0|             0|\n| 156|CASH_IN| 79644.29| C577027691|   8866017.99|    8945662.28|C1036272123|     226798.95|     147154.66|      0|             0|\n| 156|CASH_IN|304420.49| C276094466|   8945662.28|    9250082.78|C1040552729|     1160376.3|      855955.8|      0|             0|\n| 156|CASH_IN|142280.37|C1174098243|   9250082.78|    9392363.15| C508275836|     645067.07|      502786.7|      0|             0|\n+----+-------+---------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "#Writing payments to parquet\n",
    "if os.path.exists( cc.PAYMENTS_PQT_FILENAME ):\n",
    "    payments = cc.readParquet(spark, cc.PAYMENTS_PQT_FILENAME)\n",
    "else:\n",
    "    filename = cc.PAYMENTS_CSV_FILENAME\n",
    "\n",
    "    #Check if IBM Cloud Object Storage will be used\n",
    "    if USE_IBM_COS :\n",
    "        import ibmos2spark\n",
    "        # @hidden_cell\n",
    "        credentials = {\n",
    "            'endpoint': 'https://s3.eu-geo.objectstorage.service.networklayer.com',\n",
    "            'service_id': 'iam-ServiceId-d30feaff-721a-4cf0-b305-db594743f4f7',\n",
    "            'iam_service_endpoint': 'https://iam.eu-de.bluemix.net/oidc/token',\n",
    "            'api_key': 'hLy1fiHN4uR1fjiwu0IcuNxWKPk_XZc0po_xrkocAiEm'\n",
    "        }\n",
    "\n",
    "        configuration_name = 'os_7d393bdcf999474b8bdc4df51a6fb856_configs'\n",
    "        cos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n",
    "        filename = cos.url('PS_20174392719_1491204439457_log.csv', 'advanceddatasciencecapstone-donotdelete-pr-jfzvg92smkwger')\n",
    "\n",
    "    #\n",
    "    # Workaround to force run SparkFiles.get on workers\n",
    "    # spark.sparkContext.parallelize(range(1)).map(lambda x: SparkFiles.get(PAYMENTS_CSV_FILENAME)).first()\n",
    "    #\n",
    "    print('Reading data from {}'.format(filename))\n",
    "    payments = spark.read.csv(filename, inferSchema=True, header=True, mode='DROPMALFORMED')\n",
    "    print('CSV file loaded!')\n",
    "\n",
    "    cc.writeParquet(payments, cc.PAYMENTS_PQT_FILENAME)\n",
    "\n",
    "print('Schema:')\n",
    "payments.printSchema()\n",
    "\n",
    "payments.createOrReplaceTempView('payments')\n",
    "print('payments view created!')\n",
    "\n",
    "payments.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Features are extracted and encoded. This notebook contains only the common part. Model specific encodings, normalizations, etc are part of the model notebooks.\n",
    "\n",
    "It can be observed that the IDs of Origin and Destination customers embed the customer type (C: Customer, M: Merchant). This allows a fast encoding of the Features. The Origin and Destination types can be also extracted as a separate features. The two variables will anywya highly correlate with the customer IDs and might result redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "+----+-------+---------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+--------------+---------+--------------+---------+\n|step|   type|   amount|   nameOrig|oldbalanceOrg|newbalanceOrig|   nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|         vOrig|vOrigType|         vDest|vDestType|\n+----+-------+---------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+--------------+---------+--------------+---------+\n| 156|CASH_IN| 27287.59|C1634109320|   8673566.52|    8700854.11|C1542157370|     558897.81|     531610.22|      0|             0|67001634109320|        C|67001542157370|        C|\n| 156|CASH_IN|165163.88|C1684617623|   8700854.11|    8866017.99|C1163394047|     272799.53|     107635.65|      0|             0|67001684617623|        C|67001163394047|        C|\n| 156|CASH_IN| 79644.29| C577027691|   8866017.99|    8945662.28|C1036272123|     226798.95|     147154.66|      0|             0|67000577027691|        C|67001036272123|        C|\n| 156|CASH_IN|304420.49| C276094466|   8945662.28|    9250082.78|C1040552729|     1160376.3|      855955.8|      0|             0|67000276094466|        C|67001040552729|        C|\n| 156|CASH_IN|142280.37|C1174098243|   9250082.78|    9392363.15| C508275836|     645067.07|      502786.7|      0|             0|67001174098243|        C|67000508275836|        C|\n+----+-------+---------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+--------------+---------+--------------+---------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "def encodeName( s ):\n",
    "    '''\n",
    "    the fuction transforms a name string of type [A-Z][0-9]+ into an integer\n",
    "\n",
    "    :param s: the string to be converted. It should be of type [A-Z][0-9]+\n",
    "    '''\n",
    "    # 1E12 is the maximum length of a string\n",
    "    return int(1E12 * ord(s[0])) + int(s[1:])\n",
    "\n",
    "udf_encodeName = udf(encodeName, LongType())\n",
    "\n",
    "payments = payments.withColumn('vOrig', udf_encodeName(payments.nameOrig)) \\\n",
    "                    .withColumn('vOrigType', substring(payments.nameOrig, 0, 1)) \\\n",
    "                    .withColumn('vDest', udf_encodeName(payments.nameDest)) \\\n",
    "                    .withColumn('vDestType', substring(payments.nameDest, 0, 1))\n",
    "\n",
    "payments.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "+---------+\n|vOrigType|\n+---------+\n|        C|\n+---------+\n\n"
    }
   ],
   "source": [
    "payments.select('vOrigType').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vOrigType does not add any information as the value is constant. We can drop the feature from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "+---------+\n|vDestType|\n+---------+\n|        M|\n|        C|\n+---------+\n\n"
    }
   ],
   "source": [
    "payments.select('vDestType').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The destination can be either a customer or a merchant. We keep the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments.createOrReplaceTempView('payments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "+---------+---------+--------+----+\n|vOrigType|vDestType|    type| cnt|\n+---------+---------+--------+----+\n|        C|        C|CASH_OUT|4116|\n|        C|        C|TRANSFER|4097|\n+---------+---------+--------+----+\n\n"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select vOrigType, vDestType, type, count(*) as cnt from payments where isFraud = 1 group by vOrigType, vDestType, type\n",
    "\"\"\" ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "As observed during the data exploration phase, the frauds affect only transactions of type CASH_OUT and TRANSFER. As both vOriginType and vDestType are of type C, the feature is not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Encoding variables ['type']....\nComplete!\n+----+---------+-------------+--------------+-------+--------------+--------------+-------+-------+\n|step|   amount|oldbalanceOrg|oldbalanceDest|   type|         vOrig|         vDest|isFraud|typeEnc|\n+----+---------+-------------+--------------+-------+--------------+--------------+-------+-------+\n| 156| 27287.59|   8673566.52|     558897.81|CASH_IN|67001634109320|67001542157370|      0|    2.0|\n| 156|165163.88|   8700854.11|     272799.53|CASH_IN|67001684617623|67001163394047|      0|    2.0|\n| 156| 79644.29|   8866017.99|     226798.95|CASH_IN|67000577027691|67001036272123|      0|    2.0|\n| 156|304420.49|   8945662.28|     1160376.3|CASH_IN|67000276094466|67001040552729|      0|    2.0|\n| 156|142280.37|   9250082.78|     645067.07|CASH_IN|67001174098243|67000508275836|      0|    2.0|\n+----+---------+-------------+--------------+-------+--------------+--------------+-------+-------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "SCALE_FEATURES = False\n",
    "\n",
    "cat_columns = ['type', 'vOrig', 'vDest']\n",
    "num_columns = ['step', 'amount', 'oldbalanceOrg', 'oldbalanceDest']\n",
    "lbl_columns = ['isFraud']\n",
    "dl_columns = []\n",
    "\n",
    "# Encode categorical variables. Columns type and nameOrig\n",
    "\n",
    "pipe_stages = [\n",
    "    StringIndexer(inputCol='type', outputCol='typeEnc')\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(stages=pipe_stages)\n",
    "\n",
    "ps = payments.select(num_columns + cat_columns + lbl_columns)\n",
    "\n",
    "if SCALE_FEATURES:\n",
    "    print('Normalizing the numerical features...')\n",
    "    mean_sttdev = payments.select([mean(c) for c in num_columns] + [stddev(c) for c in num_columns]).first()\n",
    "\n",
    "    # Generate Normalized version of the numerical features\n",
    "    for nc in num_columns:\n",
    "        ps = ps.withColumn( f'{nc}Norm', (col(nc) - mean_sttdev[f'avg({nc})']) / mean_sttdev[f'stddev_samp({nc})'] )\n",
    "        num_columns_scaled.append(f'{nc}Norm')\n",
    "\n",
    "    print('Encoding variables {}....'.format(['type'] + num_columns))\n",
    "else:\n",
    "    print('Encoding variables {}....'.format(['type']))\n",
    "\n",
    "payments_enc = pipeline.fit(ps).transform(ps) \n",
    "print('Complete!')\n",
    "\n",
    "payments_enc.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "It resulted that the selected deep learning models benefit from the additional 'step' feature. Therefore a dedicated vector is assembled for the purpose. The vector to calculate the correlation matrix over the whole dataset need the additional 'isFraud' feature, to spot possible correlations with the other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Creating features vector for correlation from columns: ['amount', 'oldbalanceOrg', 'oldbalanceDest', 'vOrig', 'vDest', 'isFraud', 'typeEnc']\ncomplete!\nCreating features vector for random forest from columns: ['amount', 'oldbalanceOrg', 'oldbalanceDest', 'vOrig', 'vDest', 'typeEnc']\ncomplete!\nIndexing features vector...\nComplete!\nCreating features vector for deep learning models from columns: ['step', 'amount', 'oldbalanceOrg', 'oldbalanceDest', 'vOrig', 'vDest', 'typeEnc']\ncomplete!\nIndexing dl_features vector...\nComplete!\n"
    }
   ],
   "source": [
    "# Add a vector column feature\n",
    "\n",
    "dl_only_columns = ['step']\n",
    "filtered_columns = dl_only_columns + ['type','vOrigType', 'vDestType']\n",
    "\n",
    "if SCALE_FEATURES:\n",
    "    corr_features_cols = [x for x in payments_enc.columns if x not in filtered_columns and x not in num_columns]\n",
    "else:\n",
    "    corr_features_cols = [x for x in payments_enc.columns if x not in filtered_columns]\n",
    "\n",
    "print('Creating features vector for correlation from columns: {}'.format(corr_features_cols))\n",
    "vassembler = VectorAssembler(inputCols=corr_features_cols,outputCol='corrFeatures')\n",
    "payments_enc = vassembler.transform(payments_enc)\n",
    "print('complete!')\n",
    "\n",
    "features_cols = [x for x in corr_features_cols if x not in lbl_columns]\n",
    "\n",
    "print('Creating features vector for random forest from columns: {}'.format(features_cols))\n",
    "vassembler = VectorAssembler(inputCols=features_cols,outputCol='features')\n",
    "payments_enc = vassembler.transform(payments_enc)\n",
    "print('complete!')\n",
    "\n",
    "print('Indexing features vector...')\n",
    "vi = VectorIndexer(inputCol=\"features\", outputCol=\"featuresIndexed\", maxCategories=10)\n",
    "payments_enc = vi.fit(payments_enc).transform(payments_enc)\n",
    "print('Complete!')\n",
    "\n",
    "dl_features_cols = dl_only_columns + features_cols\n",
    "\n",
    "print('Creating features vector for deep learning models from columns: {}'.format(dl_features_cols))\n",
    "vassembler = VectorAssembler(inputCols=dl_features_cols,outputCol='dlFeatures')\n",
    "payments_enc = vassembler.transform(payments_enc)\n",
    "print('complete!')\n",
    "\n",
    "print('Indexing dl_features vector...')\n",
    "vi = VectorIndexer(inputCol=\"dlFeatures\", outputCol=\"dlFeaturesIndexed\", maxCategories=10)\n",
    "payments_enc = vi.fit(payments_enc).transform(payments_enc)\n",
    "print('Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "+----+---------+-------------+--------------+-------+--------------+--------------+-------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|step|   amount|oldbalanceOrg|oldbalanceDest|   type|         vOrig|         vDest|isFraud|typeEnc|        corrFeatures|            features|     featuresIndexed|          dlFeatures|   dlFeaturesIndexed|\n+----+---------+-------------+--------------+-------+--------------+--------------+-------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n| 156| 27287.59|   8673566.52|     558897.81|CASH_IN|67001634109320|67001542157370|      0|    2.0|[27287.59,8673566...|[27287.59,8673566...|[27287.59,8673566...|[156.0,27287.59,8...|[156.0,27287.59,8...|\n| 156|165163.88|   8700854.11|     272799.53|CASH_IN|67001684617623|67001163394047|      0|    2.0|[165163.88,870085...|[165163.88,870085...|[165163.88,870085...|[156.0,165163.88,...|[156.0,165163.88,...|\n| 156| 79644.29|   8866017.99|     226798.95|CASH_IN|67000577027691|67001036272123|      0|    2.0|[79644.29,8866017...|[79644.29,8866017...|[79644.29,8866017...|[156.0,79644.29,8...|[156.0,79644.29,8...|\n| 156|304420.49|   8945662.28|     1160376.3|CASH_IN|67000276094466|67001040552729|      0|    2.0|[304420.49,894566...|[304420.49,894566...|[304420.49,894566...|[156.0,304420.49,...|[156.0,304420.49,...|\n| 156|142280.37|   9250082.78|     645067.07|CASH_IN|67001174098243|67000508275836|      0|    2.0|[142280.37,925008...|[142280.37,925008...|[142280.37,925008...|[156.0,142280.37,...|[156.0,142280.37,...|\n+----+---------+-------------+--------------+-------+--------------+--------------+-------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "payments_enc.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Storing to parquet file data/payments_enc.v6.parquet...\nComplete!\n"
    }
   ],
   "source": [
    "#Writing payments to parquet\n",
    "cc.writeParquet(payments_enc, cc.PAYMENTS_ENC_PQT_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The column names used for each feature vector is stored for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "writing data/payments_enc.v6.parquet.json\nComplete!\n"
    }
   ],
   "source": [
    "cc.save_feature_cols( cc.FEATURES_CONFIG_FILENAME, corr_features_cols, features_cols, dl_features_cols)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('py3': venv)",
   "language": "python3",
   "name": "python37464bitpy3venv6d6ad2ecee8946ad950cf70b9875c8c2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}